{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTy9H5NvlVl7"
   },
   "source": [
    "# Ball detection in basketball images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZJ0JU49WLDQ"
   },
   "source": [
    "We consider the task of detecting the ball in basketball images.\n",
    "For this, we use a fully convolutional neural network which is driven by a binary target containing `1`s on the pixels where the ball is and `0`s elsewhere. The heatmap output by the network is compared against the binary target.\n",
    "\n",
    "Input image | Output heatmap | Target\n",
    "--- | --- | ---\n",
    "![RGB input image](https://arena-data.keemotion.com/tmp/gva/input_image.png) | ![output heatmap](https://arena-data.keemotion.com/tmp/gva/output_heatmap.png) | ![binary target](https://arena-data.keemotion.com/tmp/gva/input_target.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkRaUms4QXGH"
   },
   "source": [
    "### Peak Local Maxima layer implementation\n",
    "We extract the local maxima from a given heatmap, somewhat similar to the function `skimage.feature.peak_local_max`. The layer should work with a batch of multiple images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOwYpNZgkzoh",
    "outputId": "aa5447dc-523e-4d15-c7f3-6ebe2f53d7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ True False False False]\n",
      "  [False False False False]\n",
      "  [False False False False]\n",
      "  [ True False False  True]]], shape=(1, 4, 4), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PeakLocalMax():\n",
    "    def __init__(self, min_distance=20, threshold_abs=0.5):\n",
    "        \"\"\"\n",
    "            Find peaks in a batch of images as boolean mask. Peaks are the local\n",
    "            maxima in a region of 2 * min_distance + 1 (i.e. peaks are separated\n",
    "            by at least min_distance).\n",
    "\n",
    "            If there are multiple local maxima with identical pixel intensities\n",
    "            inside the region defined by 'min_distance', the coordinates of all\n",
    "            such pixels are returned.\n",
    "\n",
    "            Arguments:\n",
    "                - min_distance (int): Minimum number of pixels separating peaks\n",
    "                in a region of 2 * min_distance + 1 (i.e. peaks are separated by\n",
    "                at least min_distance). To find all the local maxima, use\n",
    "                min_distance=1).\n",
    "                - threshold_abs (float): Minimum intensity of peaks.\n",
    "        \"\"\"\n",
    "        self.min_distance = min_distance\n",
    "        self.threshold_abs = threshold_abs\n",
    "\n",
    "    def __call__(self, batch_heatmap):\n",
    "        \"\"\"\n",
    "            Performs the peak-local-max operation on batch_heatmap.\n",
    "\n",
    "            Arguments:\n",
    "                - batch_heatmap: a float32 tensor of shape [B,H,W] in [0,1]\n",
    "                containing B images of width W and height H.\n",
    "            Returns:\n",
    "                Returns a boolean tensor of shape [B,H,W] with\n",
    "                - True: on local maxima.\n",
    "                - False: elsewhere.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_heatmap_with_channels = tf.expand_dims(batch_heatmap, axis=-1)\n",
    "        dilation = tf.nn.max_pool2d(batch_heatmap_with_channels, ksize=(2*self.min_distance+1), strides=1, padding='SAME')\n",
    "        dilation = dilation[:, :, :, 0]  # Remove channel axis\n",
    "\n",
    "        local_maxima = (batch_heatmap == dilation)\n",
    "        all_maxima = (batch_heatmap >= self.threshold_abs)\n",
    "        return tf.logical_and(local_maxima, all_maxima)\n",
    "\n",
    "input = np.array([[[0.5, 0, 0, 0], [0, 0, 0, 0], [0.0, 0, 0, 0], [0.76, 0, 0, 0.89]]])\n",
    "layer = PeakLocalMax(min_distance=2)\n",
    "print(layer(input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7BqXRIwwO_u"
   },
   "source": [
    "### Detection metric layer implementation\n",
    "\n",
    "Lets consider the following binary maps:\n",
    "- `batch_hitmap` has `1`s for each ball candidate and `0`s elsewhere (such map has one single pixel set to `1` per candidate)\n",
    "- `batch_target` has `1`s for every pixels on the ball and `0`s elsewhere (such map contains multiple pixels set to `1` on the ball)\n",
    "\n",
    "We compute the following detection metrics:\n",
    "- 1 true-positive for each **candidate** where there is a ball;\n",
    "- 1 false-positive for each **candidate** where there is no ball;\n",
    "- 1 true-negative for each **image** without any ball and without any candidates;\n",
    "- 1 false-negative for each **ball** that is not detected by a candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0YbjLxOSwRu1"
   },
   "outputs": [],
   "source": [
    "class ComputeElementaryMetrics():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Computes the elementary detection metrics given a map of ball\n",
    "            candidates and a target map.\n",
    "            \n",
    "            The elementary metrics are:\n",
    "                - 1 true-positive (TP) for each candidate where there is a ball\n",
    "                - 1 false-positive (FP) for each candidate where there is no ball\n",
    "                - 1 true-negative (TN) for each image without any ball and any candidates\n",
    "                - 1 false-negative (FN) for each ball that is not detected by a candidate\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, batch_hitmap, batch_target):\n",
    "        \"\"\"\n",
    "            Performs the elementary metrics computation on the batch given\n",
    "            batch_hitmap and batch_target.\n",
    "\n",
    "            Arguments:\n",
    "                - batch_hitmap: a uint8 tensor of shape [B,H,W] in {0,1}\n",
    "                containing B maps of candidates of width W and height H. It has\n",
    "                1s for each ball candidate and 0s elsewhere.\n",
    "                - batch_target: a uint8 tensor of shape [B,H,W] in {0,1}\n",
    "                containing B targets corresponding to the WxH input images. It\n",
    "                has 1s where there is a ball and 0s elsewhere.\n",
    "            \n",
    "            Returns:\n",
    "                Returns a dictionary of 1-D arrays containing the number of TP,\n",
    "                FP, TN and FN for each element of the batch.\n",
    "        \"\"\"\n",
    "        batch_hitmap_as_bool = tf.cast(batch_hitmap, tf.bool)\n",
    "        batch_target_as_bool = tf.cast(batch_target, tf.bool)\n",
    "\n",
    "        batch_TP = tf.reduce_sum(tf.cast(tf.logical_and(batch_hitmap_as_bool, batch_target_as_bool), tf.int32))\n",
    "        batch_FP = tf.reduce_sum(\n",
    "            tf.cast(tf.logical_and(batch_hitmap_as_bool, tf.logical_not(batch_target_as_bool)), tf.int32))\n",
    "\n",
    "        # TN\n",
    "        images_without_candidates = (tf.reduce_sum(batch_hitmap, axis=[1,2]) == 0)\n",
    "        targets_without_candidates = (tf.reduce_sum(batch_target, axis=[1,2]) == 0)\n",
    "        batch_TN = tf.reduce_sum(tf.cast(tf.logical_and(\n",
    "            images_without_candidates,\n",
    "            targets_without_candidates\n",
    "        ), tf.int32))\n",
    "\n",
    "        # FN\n",
    "        batch_FN = tf.reduce_sum(\n",
    "            tf.cast(tf.logical_and(tf.logical_not(batch_hitmap_as_bool), batch_target_as_bool), tf.int32))\n",
    "\n",
    "        return {\n",
    "            \"batch_TP\": batch_TP,\n",
    "            \"batch_FP\": batch_FP,\n",
    "            \"batch_TN\": batch_TN,\n",
    "            \"batch_FN\": batch_FN,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkPuQEZxxa46"
   },
   "source": [
    "### Ball Detection evaluation metrics\n",
    "\n",
    "Using the number of **true** and **false** **positives** and **negatives** computed on batch of data, you are asked to compute relevant detection metrics on the whole dataset (for each epoch) and print them to standard output. Please include succinct interpretation of the metrics you selected.\n",
    "\n",
    "For this, we provide the structure of `ComputeDetectionMetricsCallback` that implements callbacks called before and after each batch and each epochs. They  receive a `state` dictionary containing the current elementary metrics, as well as other state variables that are not necessary here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8NYupYBxZ_z"
   },
   "outputs": [],
   "source": [
    "class ComputeDetectionMetricsCallback():\n",
    "    ### TO COMPLETE\n",
    "    def __init__(self):\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "        self.f1_score = 1\n",
    "\n",
    "    def on_epoch_begin(self, state):\n",
    "        \"\"\" called at the begining of each epoch \"\"\"\n",
    "        # reset metrics\n",
    "        self.precision = 0\n",
    "        self.recall = 0\n",
    "        self.f1_score = 0\n",
    "        \n",
    "        self.num_batches = 0\n",
    "\n",
    "    def on_epoch_end(self, state):\n",
    "        \"\"\" called at the end of each epoch \"\"\"\n",
    "        print(f'Precision: {self.precision}')\n",
    "        print(f'Recall: {self.recall}')\n",
    "        print(f'F1 score: {self.f1_score}')\n",
    "\n",
    "    def on_batch_begin(self, state):\n",
    "        \"\"\" called before processing each batch \"\"\"\n",
    "        self.num_batches += 1\n",
    "\n",
    "    def on_batch_end(self, state):\n",
    "        \"\"\" called after processing each batch \"\"\"\n",
    "        # state contains \"batch_TP\", \"batch_FP\", \"batch_TN\", \"batch_FN\" for the current batch\n",
    "        \n",
    "        # Precision calculates what fraction of ball detections are real ball detections\n",
    "        batch_precision = state['batch_TP'] / (state['batch_TP'] + state['batch_FP'])\n",
    "\n",
    "        # Recall tells us what fraction of real balls are detected\n",
    "        batch_recall = state['batch_TP'] / (state['batch_TP'] + state['batch_FN'])\n",
    "\n",
    "        # F1 score is a method to combine precision and recall\n",
    "        batch_f1_score = (2 * batch_precision * batch_recall) / (batch_precision + batch_recall)\n",
    "        \n",
    "        # Update\n",
    "        self.precision = (1/self.num_batches) * batch_precision + ((self.num_batches-1) / self.num_batches) * self.precision\n",
    "        self.recall = (1 / self.num_batches) * batch_recall + ((self.num_batches - 1) / self.num_batches) * self.recall\n",
    "        self.f1_score = (1 / self.num_batches) * batch_f1_score + ((self.num_batches - 1) / self.num_batches) * self.f1_score\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Technical_test_Derk_Mus (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06bb6194a28246f2a01f5a96fc7d88ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25920446fb77497298d13147ddc2b9fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "527f1dd5ab234259895b5ddea79ff02e": {
     "model_module": "@jupyter-widgets/output",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_06bb6194a28246f2a01f5a96fc7d88ba",
      "msg_id": "",
      "outputs": [
       {
        "metadata": {
         "tags": []
        },
        "output_type": "stream",
        "stream": "stdout",
        "text": "{'batch': 18,\n 'batch_FN': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int32),\n 'batch_FP': array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int32),\n 'batch_TN': array([1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1], dtype=int32),\n 'batch_TP': array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0], dtype=int32),\n 'epoch': 1,\n 'loss': 0.0003952446,\n 'subset': 'training'}\n"
       }
      ]
     }
    },
    "6c3e37782d8e4ad29c9058467b745f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "epoch",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_a4148d3bcb63452d9fb1466dfe91e9e5",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_e494d6a46df44653aca658bc494f1538",
      "value": 0
     }
    },
    "a4148d3bcb63452d9fb1466dfe91e9e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a50890a83c6d43e48a7153bf72f31e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": true,
      "description": "batch",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_ed438e856d46456489a73d4ce579ac91",
      "max": 70,
      "min": 0,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_25920446fb77497298d13147ddc2b9fd",
      "value": 17
     }
    },
    "b18e6b1c57654d69a267bf70da999b1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da7c5a23e3c54dc0a1e6c972a013f0a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [
       "widget-interact"
      ],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c3e37782d8e4ad29c9058467b745f6c",
       "IPY_MODEL_a50890a83c6d43e48a7153bf72f31e3c",
       "IPY_MODEL_527f1dd5ab234259895b5ddea79ff02e"
      ],
      "layout": "IPY_MODEL_b18e6b1c57654d69a267bf70da999b1e"
     }
    },
    "e494d6a46df44653aca658bc494f1538": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "ed438e856d46456489a73d4ce579ac91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
